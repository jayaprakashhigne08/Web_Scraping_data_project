{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43e7f0f-345b-4446-8317-2ac32a15ec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\avg001\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\avg001\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1e1c7e-5dff-4917-aa61-e108b3a4c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   import libraries \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests    \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28516518-2779-4a61-810f-8260df2c262f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     row\u001b[38;5;241m=\u001b[39m[tr\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m tr \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m     25\u001b[0m     l\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df)\n\u001b[1;32m---> 26\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[l]\u001b[38;5;241m=\u001b[39mrow\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:885\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    884\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 885\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1883\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1880\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1882\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 1883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_missing(indexer, value)\n\u001b[0;32m   1884\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1887\u001b[0m     \u001b[38;5;66;03m# must come after setting of missing\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:2219\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   2216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[0;32m   2217\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[0;32m   2218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m-> 2219\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2221\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[0;32m   2223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n\u001b[0;32m   2224\u001b[0m     \u001b[38;5;66;03m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[0;32m   2225\u001b[0m     \u001b[38;5;66;03m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "url = 'https://www.iplt20.com/auction/2023'\n",
    "r=requests.get(url)\n",
    "#print(r)\n",
    "soup=BeautifulSoup(r.text,\"lxml\")\n",
    "#print(soup)\n",
    "table=soup.find(\"table\", class_ = \"ih-td-tab\")\n",
    "#print(table)\n",
    "title=soup.find_all(\"th\")\n",
    "#print(title)\n",
    "\n",
    "header=[]\n",
    "for i in title:\n",
    "    name = i.text\n",
    "    header.append(name)\n",
    "\n",
    "#print(header)\n",
    "\n",
    "df=pd.DataFrame(columns=header)\n",
    "#print(df)\n",
    "rows=table.find_all(\"tr\")\n",
    "\n",
    "for i in rows[1:]:\n",
    "    data=i.find_all('td')\n",
    "    row=[tr.text for tr in data]\n",
    "    l=len(df)\n",
    "    df.loc[l]=row\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74b8644c-b697-4b44-b29b-eed107d33530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          TEAM FUNDS REMAINING OVERSEAS PLAYERS TOTAL PLAYERS\n",
      "0          Chennai Super Kings    ₹1,50,00,000                8            25\n",
      "1               Delhi Capitals    ₹4,45,00,000                8            25\n",
      "2               Gujarat Titans    ₹4,45,00,000                8            25\n",
      "3        Kolkata Knight Riders    ₹1,65,00,000                8            22\n",
      "4         Lucknow Super Giants    ₹3,55,00,000                8            25\n",
      "5               Mumbai Indians       ₹5,00,000                8            24\n",
      "6                 Punjab Kings   ₹12,20,00,000                7            22\n",
      "7             Rajasthan Royals    ₹3,35,00,000                8            25\n",
      "8  Royal Challengers Bangalore    ₹1,75,00,000                8            25\n",
      "9          Sunrisers Hyderabad    ₹6,55,00,000                8            25\n",
      "Data saved to ipl_Auction_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.iplt20.com/auction/2023'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "# Find the table\n",
    "table = soup.find(\"table\", class_=\"ih-td-tab\")\n",
    "if table is None:\n",
    "    print(\"No table found. Check the class name or HTML structure.\")\n",
    "    exit()\n",
    "\n",
    "# Extract headers\n",
    "title = table.find_all(\"th\")\n",
    "header = [i.text.strip() for i in title]\n",
    "\n",
    "# Create a DataFrame with the headers\n",
    "df = pd.DataFrame(columns=header)\n",
    "\n",
    "# Extract rows\n",
    "rows = table.find_all(\"tr\")  # Find all rows in the table\n",
    "for row in rows[1:]:  # Skip the header row\n",
    "    data = row.find_all(\"td\")\n",
    "    row_data = [td.text.strip() for td in data]\n",
    "    \n",
    "    # Ensure the row matches the header length\n",
    "    if len(row_data) == len(header):\n",
    "        df.loc[len(df)] = row_data\n",
    "    else:\n",
    "        print(f\"Skipping mismatched row: {row_data}\")\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save to Excel file\n",
    "excel_filename = \"ipl_Auction_data.xlsx\"\n",
    "df.to_excel(excel_filename, index=False)\n",
    "print(f\"Data saved to {excel_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2eafe-f23d-444f-b277-a6cc989e0342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
